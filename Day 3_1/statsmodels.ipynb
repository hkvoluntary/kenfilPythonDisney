{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNN4zObpsQunXuY0gcP2N++"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Stepwise Regression with statsmodels\n","\n","    * Forward Selection: Starts with no features and adds them one at a time based on a criterion (e.g., p-value).\n","    * Backward Elimination: Starts with all features and removes them one at a time based on a criterion.\n","\n","Detailed Steps\n","\n","    1. Prepare the Data: Load or generate your dataset.\n","    2. Define the Forward Selection Function: Implement the logic to add features.\n","    3. Define the Backward Elimination Function: Implement the logic to remove features.\n","    4. Evaluate the Results: Check the final model summary."],"metadata":{"id":"gzxbz_WPEpKN"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"KteGghV-Ecr5","executionInfo":{"status":"ok","timestamp":1726762763430,"user_tz":420,"elapsed":4990,"user":{"displayName":"Ng Ted","userId":"06817628253326971985"}}},"outputs":[],"source":["# Step 1: Prepare the Data\n","import pandas as pd\n","import numpy as np\n","from sklearn.datasets import make_regression\n","from statsmodels.api import OLS, add_constant\n","from sklearn.model_selection import train_test_split\n","\n","# Generate synthetic data\n","X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\n","feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n","df = pd.DataFrame(X, columns=feature_names)\n","df['target'] = y\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n"]},{"cell_type":"code","source":["# Step 2: Define Forward Selection\n","# Start with no features.\n","# Iteratively add features based on the lowest p-value.\n","\n","def forward_selection(X, y, threshold_in=0.05):\n","    initial_features = []\n","    best_features = []\n","\n","    while True:\n","        remaining_features = set(X.columns) - set(initial_features)\n","        best_pvalue = float('inf')\n","        best_feature = None\n","\n","        for feature in remaining_features:\n","            model = OLS(y, add_constant(X[initial_features + [feature]])).fit()\n","            pvalue = model.pvalues[feature]\n","\n","            if pvalue < best_pvalue:\n","                best_pvalue = pvalue\n","                best_feature = feature\n","\n","        if best_pvalue < threshold_in:\n","            initial_features.append(best_feature)\n","            best_features.append(best_feature)\n","        else:\n","            break\n","\n","    return best_features\n"],"metadata":{"id":"_3-gxpiTE7pP","executionInfo":{"status":"ok","timestamp":1726763205578,"user_tz":420,"elapsed":545,"user":{"displayName":"Ng Ted","userId":"06817628253326971985"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Step 3: Define Backward Elimination\n","# Start with all features.\n","# Remove the feature with the highest p-value if it exceeds the threshold.\n","def backward_elimination(X, y, threshold_out=0.05):\n","    features = list(X.columns)\n","\n","    while True:\n","        model = OLS(y, add_constant(X[features])).fit()\n","        pvalues = model.pvalues[1:]  # Ignore constant\n","\n","        worst_pvalue = pvalues.max()\n","        if worst_pvalue > threshold_out:\n","            worst_feature = pvalues.idxmax()\n","            features.remove(worst_feature)\n","        else:\n","            break\n","\n","    return features\n"],"metadata":{"id":"K7Vo1YgBFBcA","executionInfo":{"status":"ok","timestamp":1726763209406,"user_tz":420,"elapsed":581,"user":{"displayName":"Ng Ted","userId":"06817628253326971985"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Step 4: Execute and Evaluate\n","# Forward Selection\n","selected_features_forward = forward_selection(X_train, y_train)\n","print(\"Selected features after forward selection:\", selected_features_forward)\n","\n","# Backward Elimination\n","selected_features_backward = backward_elimination(X_train, y_train)\n","print(\"Selected features after backward elimination:\", selected_features_backward)\n","\n","# Fit final model with selected features\n","final_model = OLS(y_train, add_constant(X_train[selected_features_forward])).fit()\n","print(final_model.summary())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuK6xWhlFDnu","executionInfo":{"status":"ok","timestamp":1726763213469,"user_tz":420,"elapsed":566,"user":{"displayName":"Ng Ted","userId":"06817628253326971985"}},"outputId":"d02b415b-97b1-4436-c21b-1ccc622e9df8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected features after forward selection: ['feature_6', 'feature_4', 'feature_9', 'feature_5', 'feature_3', 'feature_1', 'feature_0', 'feature_7', 'feature_2', 'feature_8']\n","Selected features after backward elimination: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                 target   R-squared:                       1.000\n","Model:                            OLS   Adj. R-squared:                  1.000\n","Method:                 Least Squares   F-statistic:                 2.259e+07\n","Date:                Thu, 19 Sep 2024   Prob (F-statistic):          1.33e-220\n","Time:                        16:26:53   Log-Likelihood:                 73.260\n","No. Observations:                  80   AIC:                            -124.5\n","Df Residuals:                      69   BIC:                            -98.32\n","Df Model:                          10                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const          0.0176      0.012      1.452      0.151      -0.007       0.042\n","feature_6     87.0714      0.013   6837.063      0.000      87.046      87.097\n","feature_4     93.6131      0.013   7482.509      0.000      93.588      93.638\n","feature_9     70.9089      0.014   5063.840      0.000      70.881      70.937\n","feature_5     70.6369      0.013   5354.563      0.000      70.611      70.663\n","feature_3     63.6436      0.013   4800.952      0.000      63.617      63.670\n","feature_1     54.1378      0.014   3736.349      0.000      54.109      54.167\n","feature_0     16.7712      0.014   1242.149      0.000      16.744      16.798\n","feature_7     10.4388      0.013    825.606      0.000      10.414      10.464\n","feature_2      5.1810      0.014    371.872      0.000       5.153       5.209\n","feature_8      3.1569      0.012    270.592      0.000       3.134       3.180\n","==============================================================================\n","Omnibus:                        6.783   Durbin-Watson:                   2.156\n","Prob(Omnibus):                  0.034   Jarque-Bera (JB):                6.239\n","Skew:                          -0.553   Prob(JB):                       0.0442\n","Kurtosis:                       3.805   Cond. No.                         1.95\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]}]}]}